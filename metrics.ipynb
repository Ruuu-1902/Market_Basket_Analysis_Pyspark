{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz2wFvVzcrqx"
      },
      "source": [
        "Traditional Market Basket Analysis (MBA) using FP-Growth identifies frequent product combinations based only on static measures like support and confidence.\n",
        "However, these static rules overlook how purchasing behavior evolves over time, how strong or stable these associations are, and how they can be used for prediction of future purchases.\n",
        "\n",
        "This project aims to design a Dynamic Market Basket Framework that not only extracts association rules using FP-Growth but also introduces three novel indices ‚Äî Affinity Strength Index (ASI), Temporal Stability Index (TSI), and Diversity Spread Index (DSI) ‚Äî to enhance interpretability.\n",
        "\n",
        "Additionally, the project integrates a Machine Learning model to predict the next likely product."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcRoYoPen5m0",
        "outputId": "86b030bc-532d-4141-b538-b20780304162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "# Download Java Virtual Machine (JVM)\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFsPohnmoRZ-"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGHK1mpXp674",
        "outputId": "34eb014b-93da-448a-e43c-7a0847f10e37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Spark version: 3.5.1\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create or get existing Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"MyColabSparkApp\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Check Spark version\n",
        "print(\"‚úÖ Spark version:\", spark.version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vWtwWZHq0Or"
      },
      "outputs": [],
      "source": [
        "# Step 5: Load all CSV files from local Colab working directory\n",
        "# Make sure you've uploaded them via the Files sidebar or using files.upload()\n",
        "\n",
        "aisles = spark.read.csv(\"/content/aisles.csv\", header=True, inferSchema=True)\n",
        "departments = spark.read.csv(\"/content/departments.csv\", header=True, inferSchema=True)\n",
        "order_products__prior = spark.read.csv(\"/content/order_products__prior.csv\", header=True, inferSchema=True)\n",
        "order_products__train = spark.read.csv(\"/content/order_products__train.csv\", header=True, inferSchema=True)\n",
        "orders = spark.read.csv(\"/content/orders.csv\", header=True, inferSchema=True)\n",
        "products = spark.read.csv(\"/content/products.csv\", header=True, inferSchema=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gh2fkTvzXnCM"
      },
      "outputs": [],
      "source": [
        "# run this cell first\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import col, explode, array_distinct, size, collect_set, countDistinct\n",
        "from pyspark.ml.fpm import FPGrowth\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rttbh2wWU5U5"
      },
      "source": [
        "**1) Combine prior + train and join metadata**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w01qQJqG6d2i",
        "outputId": "a293e46d-7225-44e3-a48e-a52a4ac89733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+-------+----------+---------------------------------------------+----------------------+----------+---------+\n",
            "|order_id|user_id|product_id|                                 product_name|                 aisle|department|order_dow|\n",
            "+--------+-------+----------+---------------------------------------------+----------------------+----------+---------+\n",
            "|       6|  22352|     40462|                                      Cleanse|          refrigerated| beverages|        1|\n",
            "|       6|  22352|     15873|                  Dryer Sheets Geranium Scent|               laundry| household|        1|\n",
            "|       6|  22352|     41897|Clean Day Lavender Scent Room Freshener Spray|air fresheners candles| household|        1|\n",
            "|       8|   3107|     23423|                Original Hawaiian Sweet Rolls|            buns rolls|    bakery|        4|\n",
            "|      14|  18194|     20392|                Hair Bender Whole Bean Coffee|                coffee| beverages|        3|\n",
            "+--------+-------+----------+---------------------------------------------+----------------------+----------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create temporary views\n",
        "aisles.createOrReplaceTempView(\"aisles\")\n",
        "departments.createOrReplaceTempView(\"departments\")\n",
        "orders.createOrReplaceTempView(\"orders\")\n",
        "order_products__prior.createOrReplaceTempView(\"order_products_prior\")\n",
        "order_products__train.createOrReplaceTempView(\"order_products_train\")\n",
        "products.createOrReplaceTempView(\"products\")\n",
        "\n",
        "# Combine prior + train\n",
        "query_union = \"\"\"\n",
        "SELECT * FROM order_products_prior\n",
        "UNION ALL\n",
        "SELECT * FROM order_products_train\n",
        "\"\"\"\n",
        "spark.sql(query_union).createOrReplaceTempView(\"order_products_all\")\n",
        "\n",
        "# Join all datasets together using INNER JOIN to avoid nulls\n",
        "query_joined = \"\"\"\n",
        "SELECT\n",
        "    opa.order_id,\n",
        "    o.user_id,\n",
        "    opa.product_id,\n",
        "    p.product_name,\n",
        "    p.aisle_id,\n",
        "    p.department_id,\n",
        "    a.aisle,\n",
        "    d.department,\n",
        "    o.order_number,\n",
        "    o.order_dow,\n",
        "    o.order_hour_of_day,\n",
        "    o.days_since_prior_order\n",
        "FROM order_products_all opa\n",
        "INNER JOIN products p       ON opa.product_id = p.product_id\n",
        "INNER JOIN aisles a         ON p.aisle_id = a.aisle_id\n",
        "INNER JOIN departments d    ON p.department_id = d.department_id\n",
        "INNER JOIN orders o         ON opa.order_id = o.order_id\n",
        "\"\"\"\n",
        "\n",
        "# Create the final combined view\n",
        "instacart_full = spark.sql(query_joined)\n",
        "instacart_full.createOrReplaceTempView(\"instacart_full\")\n",
        "\n",
        "# Show a sample\n",
        "instacart_full.select(\n",
        "    \"order_id\", \"user_id\", \"product_id\", \"product_name\", \"aisle\", \"department\", \"order_dow\"\n",
        ").show(5, truncate=80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_apW9lPXtGF"
      },
      "source": [
        "**Preparing your transaction data for market basket analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8XOXt9TyyoW",
        "outputId": "85776a7a-ed72-48f7-eac2-a341a6aff0ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total transactions: 108610\n",
            "+--------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|order_id|items                                                                                                                                                                             |\n",
            "+--------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|1       |[49683, 22035, 47209, 43633, 49302, 11109, 13176, 10246]                                                                                                                          |\n",
            "|3       |[46667, 21903, 17461, 32665, 33754, 24838, 17668, 17704]                                                                                                                          |\n",
            "|5       |[12962, 48825, 18569, 27360, 13245, 6184, 46522, 47209, 9633, 6348, 23909, 45698, 27966, 40878, 38693, 20914, 41176, 37011, 15005, 47329, 8479, 13176, 48370, 48002, 24773, 48366]|\n",
            "|6       |[15873, 41897, 40462]                                                                                                                                                             |\n",
            "|9       |[18362, 3990, 29193, 34203, 14183, 31506, 432, 11182, 27366, 47890, 2014, 21405, 23288, 44533, 14992]                                                                             |\n",
            "+--------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# create 'items' as array of string product_ids per order\n",
        "tx = (order_products_all\n",
        "      .withColumn(\"product_id_str\", F.col(\"product_id\").cast(\"string\"))\n",
        "      .groupBy(\"order_id\")\n",
        "      .agg(collect_set(\"product_id_str\").alias(\"items\")))\n",
        "\n",
        "print(\"Total transactions:\", tx.count())\n",
        "tx.show(5, truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5dndu0DZsSl"
      },
      "source": [
        "FREQUENT ITEMS AND ASSOCIATION RULES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMcXznMk0Oez",
        "outputId": "3b6fddfc-21d5-4234-af30-9606663c7d54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frequent itemsets (sample):\n",
            "+-------+-----+\n",
            "|items  |freq |\n",
            "+-------+-----+\n",
            "|[24852]|15736|\n",
            "|[13176]|12871|\n",
            "|[21137]|8867 |\n",
            "|[21903]|8135 |\n",
            "|[47209]|6566 |\n",
            "|[47626]|6104 |\n",
            "|[47766]|6084 |\n",
            "|[16797]|5224 |\n",
            "|[26209]|4911 |\n",
            "|[27966]|4648 |\n",
            "+-------+-----+\n",
            "only showing top 10 rows\n",
            "\n",
            "Association rules (sample):\n",
            "+--------------+----------+-------------------+------------------+---------------------+\n",
            "|antecedent    |consequent|confidence         |lift              |support              |\n",
            "+--------------+----------+-------------------+------------------+---------------------+\n",
            "|[27966, 47209]|[13176]   |0.4994413407821229 |4.214460727398521 |0.004115643126783906 |\n",
            "|[19057, 21137]|[13176]   |0.4200743494423792 |3.5447342936008703|0.0020808397016849277|\n",
            "|[5876, 47209] |[13176]   |0.4172461752433936 |3.5208691704750974|0.002762176595156984 |\n",
            "|[4957]        |[33754]   |0.4152542372881356 |48.91622853781389 |0.0022557775527115367|\n",
            "|[30391, 47209]|[13176]   |0.41509433962264153|3.502711228841201 |0.0024307154037381457|\n",
            "|[47209, 21137]|[13176]   |0.4136085626911315 |3.490173723400186 |0.0049811251265997605|\n",
            "|[27966, 21903]|[13176]   |0.4073482428115016 |3.4373469545301214|0.002347850105883436 |\n",
            "|[33787]       |[33754]   |0.403747870528109  |47.56079850114742 |0.0021821195101740173|\n",
            "|[22935, 47209]|[13176]   |0.3927392739273927 |3.3140713651817357|0.0021913267654912073|\n",
            "|[5876, 21137] |[13176]   |0.3914590747330961 |3.303268596594015 |0.002025596169781788 |\n",
            "+--------------+----------+-------------------+------------------+---------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "fp = FPGrowth(itemsCol=\"items\", minSupport=0.002, minConfidence=0.15)\n",
        "model = fp.fit(tx)\n",
        "\n",
        "freq_itemsets = model.freqItemsets  # columns: items, freq\n",
        "rules = model.associationRules      # columns: antecedent, consequent, confidence, support, lift\n",
        "\n",
        "print(\"Frequent itemsets (sample):\")\n",
        "freq_itemsets.orderBy(col(\"freq\").desc()).show(10, truncate=False)\n",
        "\n",
        "print(\"Association rules (sample):\")\n",
        "rules.orderBy(col(\"confidence\").desc()).show(10, truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# METRIC 1 - ASI - Association Strength Index\n",
        "Support tells you how often A and B occur together.\n",
        "\n",
        "Confidence tells you how likely B appears when A is bought.\n",
        "\n",
        "Lift tells you how much stronger that relationship is compared to random chance.\n",
        "\n",
        "But sometimes:\n",
        "\n",
        "High support = popular products bought often ‚Üí may not mean a strong relation.\n",
        "\n",
        "High confidence = can be misleading if one product is common across all baskets.\n",
        "\n",
        "**So, ASI was proposed to measure how consistently two items appear together across transactions, capturing both strength and stability of their relationship.**"
      ],
      "metadata": {
        "id": "avWosSFGSQyX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ixXwBEA0nWZ",
        "outputId": "b1d2d63a-3120-4308-8b6d-e4baed0bd211"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+---------+-----+-----+-------------------+\n",
            "|itemA|itemB|freq_pair|freqA|freqB|ASI                |\n",
            "+-----+-----+---------+-----+-----+-------------------+\n",
            "|4957 |33754|245      |590  |922  |0.19337016574585636|\n",
            "|33787|33754|237      |587  |922  |0.18632075471698117|\n",
            "|2295 |15290|290      |941  |1417 |0.1402321083172147 |\n",
            "|26209|47626|1182     |4911 |6104 |0.12020746465981896|\n",
            "|21137|13176|2326     |8867 |12871|0.11982279002678756|\n",
            "|35221|44632|465      |1608 |2740 |0.11975276847798093|\n",
            "|21709|35221|292      |1124 |1608 |0.11967213114754098|\n",
            "|47209|13176|2036     |6566 |12871|0.11700476984081373|\n",
            "|24964|22935|715      |3543 |3601 |0.11121480790169544|\n",
            "|31717|26209|704      |2628 |4911 |0.10299926847110462|\n",
            "|27966|21137|1224     |4648 |8867 |0.0995850622406639 |\n",
            "|47766|24852|1855     |6084 |15736|0.09291259704482845|\n",
            "|27966|13176|1487     |4648 |12871|0.09275199600798403|\n",
            "|21903|13176|1782     |8135 |12871|0.09269662921348315|\n",
            "|47209|21137|1308     |6566 |8867 |0.09260176991150443|\n",
            "|47766|47626|1029     |6084 |6104 |0.09221256384980732|\n",
            "|21938|24184|342      |1935 |2167 |0.09095744680851064|\n",
            "|27966|47209|895      |4648 |6566 |0.08673321058242078|\n",
            "|21709|44632|298      |1124 |2740 |0.08356702187324734|\n",
            "|21903|21137|1304     |8135 |8867 |0.08306790673971207|\n",
            "+-----+-----+---------+-----+-----+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# total number of transactions\n",
        "total_tx = tx.count()\n",
        "\n",
        "# singleton frequencies\n",
        "singles = freq_itemsets.filter(size(col(\"items\")) == 1) \\\n",
        "    .select(col(\"items\").getItem(0).alias(\"item\"), col(\"freq\").alias(\"freq_single\"))\n",
        "\n",
        "# pair frequencies\n",
        "pairs = freq_itemsets.filter(size(col(\"items\")) == 2) \\\n",
        "    .select(col(\"items\").getItem(0).alias(\"itemA\"), col(\"items\").getItem(1).alias(\"itemB\"), col(\"freq\").alias(\"freq_pair\"))\n",
        "\n",
        "# Join singles to pairs to compute ASI\n",
        "asi_df = (pairs.join(singles.withColumnRenamed(\"item\",\"itemA\").withColumnRenamed(\"freq_single\",\"freqA\"), on=\"itemA\")\n",
        "              .join(singles.withColumnRenamed(\"item\",\"itemB\").withColumnRenamed(\"freq_single\",\"freqB\"), on=\"itemB\"))\n",
        "\n",
        "# compute ASI\n",
        "asi_df = asi_df.withColumn(\n",
        "    \"ASI\",\n",
        "    (col(\"freq_pair\")/F.lit(total_tx)) / ((col(\"freqA\") + col(\"freqB\") - col(\"freq_pair\"))/F.lit(total_tx))\n",
        ")\n",
        "\n",
        "# Order by ASI descending\n",
        "asi_df.select(\"itemA\",\"itemB\",\"freq_pair\",\"freqA\",\"freqB\",\"ASI\").orderBy(col(\"ASI\").desc()).show(20, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "945HvayEf99R",
        "outputId": "78dad686-393a-41ac-cb81-cb005c01ea21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîπ Association Rules (A ‚Üí B):\n",
            "+-------------+-------+-----------------+-------+------+\n",
            "|Rule_A_to_B  |support|confidence_A_to_B|lift   |ASI   |\n",
            "+-------------+-------+-----------------+-------+------+\n",
            "|4957 ‚Üí 33754 |0.0023 |0.4153           |48.9162|0.1934|\n",
            "|33787 ‚Üí 33754|0.0022 |0.4037           |47.5608|0.1863|\n",
            "|2295 ‚Üí 15290 |0.0027 |0.3082           |23.6215|0.1402|\n",
            "|26209 ‚Üí 47626|0.0109 |0.2407           |4.2826 |0.1202|\n",
            "|21137 ‚Üí 13176|0.0214 |0.2623           |2.2136 |0.1198|\n",
            "|35221 ‚Üí 44632|0.0043 |0.2892           |11.4627|0.1198|\n",
            "|21709 ‚Üí 35221|0.0027 |0.2598           |17.5469|0.1197|\n",
            "|47209 ‚Üí 13176|0.0187 |0.3101           |2.6166 |0.117 |\n",
            "|24964 ‚Üí 22935|0.0066 |0.2018           |6.0867 |0.1112|\n",
            "|31717 ‚Üí 26209|0.0065 |0.2679           |5.9244 |0.103 |\n",
            "|27966 ‚Üí 21137|0.0113 |0.2633           |3.2256 |0.0996|\n",
            "|47766 ‚Üí 24852|0.0171 |0.3049           |2.1044 |0.0929|\n",
            "|27966 ‚Üí 13176|0.0137 |0.3199           |2.6996 |0.0928|\n",
            "|21903 ‚Üí 13176|0.0164 |0.2191           |1.8484 |0.0927|\n",
            "|47209 ‚Üí 21137|0.012  |0.1992           |2.4401 |0.0926|\n",
            "|47766 ‚Üí 47626|0.0095 |0.1691           |3.0094 |0.0922|\n",
            "|21938 ‚Üí 24184|0.0031 |0.1767           |8.8584 |0.091 |\n",
            "|27966 ‚Üí 47209|0.0082 |0.1926           |3.1851 |0.0867|\n",
            "|21709 ‚Üí 44632|0.0027 |0.2651           |10.5092|0.0836|\n",
            "|21903 ‚Üí 21137|0.012  |0.1603           |1.9634 |0.0831|\n",
            "+-------------+-------+-----------------+-------+------+\n",
            "only showing top 20 rows\n",
            "\n",
            "üîπ Association Rules (B ‚Üí A):\n",
            "+-------------+-------+-----------------+-------+------+\n",
            "|Rule_B_to_A  |support|confidence_B_to_A|lift   |ASI   |\n",
            "+-------------+-------+-----------------+-------+------+\n",
            "|33754 ‚Üí 4957 |0.0023 |0.2657           |48.9162|0.1934|\n",
            "|33754 ‚Üí 33787|0.0022 |0.257            |47.5608|0.1863|\n",
            "|15290 ‚Üí 2295 |0.0027 |0.2047           |23.6215|0.1402|\n",
            "|47626 ‚Üí 26209|0.0109 |0.1936           |4.2826 |0.1202|\n",
            "|13176 ‚Üí 21137|0.0214 |0.1807           |2.2136 |0.1198|\n",
            "|44632 ‚Üí 35221|0.0043 |0.1697           |11.4627|0.1198|\n",
            "|35221 ‚Üí 21709|0.0027 |0.1816           |17.5469|0.1197|\n",
            "|13176 ‚Üí 47209|0.0187 |0.1582           |2.6166 |0.117 |\n",
            "|22935 ‚Üí 24964|0.0066 |0.1986           |6.0867 |0.1112|\n",
            "|26209 ‚Üí 31717|0.0065 |0.1434           |5.9244 |0.103 |\n",
            "|21137 ‚Üí 27966|0.0113 |0.138            |3.2256 |0.0996|\n",
            "|24852 ‚Üí 47766|0.0171 |0.1179           |2.1044 |0.0929|\n",
            "|13176 ‚Üí 27966|0.0137 |0.1155           |2.6996 |0.0928|\n",
            "|13176 ‚Üí 21903|0.0164 |0.1385           |1.8484 |0.0927|\n",
            "|21137 ‚Üí 47209|0.012  |0.1475           |2.4401 |0.0926|\n",
            "|47626 ‚Üí 47766|0.0095 |0.1686           |3.0094 |0.0922|\n",
            "|24184 ‚Üí 21938|0.0031 |0.1578           |8.8584 |0.091 |\n",
            "|47209 ‚Üí 27966|0.0082 |0.1363           |3.1851 |0.0867|\n",
            "|44632 ‚Üí 21709|0.0027 |0.1088           |10.5092|0.0836|\n",
            "|21137 ‚Üí 21903|0.012  |0.1471           |1.9634 |0.0831|\n",
            "+-------------+-------+-----------------+-------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, round, concat_ws, lit\n",
        "\n",
        "# Compute all metrics\n",
        "asi_rules = asi_df.withColumn(\n",
        "    \"support\", col(\"freq_pair\") / F.lit(total_tx)\n",
        ").withColumn(\n",
        "    \"confidence_A_to_B\", col(\"freq_pair\") / col(\"freqA\")\n",
        ").withColumn(\n",
        "    \"confidence_B_to_A\", col(\"freq_pair\") / col(\"freqB\")\n",
        ").withColumn(\n",
        "    \"lift\",\n",
        "    (col(\"freq_pair\") / F.lit(total_tx)) /\n",
        "    ((col(\"freqA\") / F.lit(total_tx)) * (col(\"freqB\") / F.lit(total_tx)))\n",
        ").withColumn(\n",
        "    \"ASI\", round(col(\"ASI\"), 4)\n",
        ").withColumn(\n",
        "    \"support\", round(col(\"support\"), 4)\n",
        ").withColumn(\n",
        "    \"confidence_A_to_B\", round(col(\"confidence_A_to_B\"), 4)\n",
        ").withColumn(\n",
        "    \"confidence_B_to_A\", round(col(\"confidence_B_to_A\"), 4)\n",
        ").withColumn(\n",
        "    \"lift\", round(col(\"lift\"), 4)\n",
        ")\n",
        "\n",
        "# ü™Ñ Create readable rule strings (like Apriori)\n",
        "asi_rules = asi_rules.withColumn(\n",
        "    \"Rule_A_to_B\", concat_ws(\" ‚Üí \", col(\"itemA\"), col(\"itemB\"))\n",
        ").withColumn(\n",
        "    \"Rule_B_to_A\", concat_ws(\" ‚Üí \", col(\"itemB\"), col(\"itemA\"))\n",
        ")\n",
        "\n",
        "# üîπ Show Top Rules (A‚ÜíB)\n",
        "print(\"üîπ Association Rules (A ‚Üí B):\")\n",
        "asi_rules.select(\n",
        "    \"Rule_A_to_B\", \"support\", \"confidence_A_to_B\", \"lift\", \"ASI\"\n",
        ").orderBy(col(\"ASI\").desc()).show(20, truncate=False)\n",
        "\n",
        "# üîπ Show Reverse Rules (B ‚Üí A)\n",
        "print(\"üîπ Association Rules (B ‚Üí A):\")\n",
        "asi_rules.select(\n",
        "    \"Rule_B_to_A\", \"support\", \"confidence_B_to_A\", \"lift\", \"ASI\"\n",
        ").orderBy(col(\"ASI\").desc()).show(20, truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cove8b26spfF"
      },
      "source": [
        "# METRIC 2 Temporal index - day of week  -\n",
        "\n",
        "TSI (Temporal Stability Index) measures how consistent a relationship between products is over time.\n",
        "\n",
        "It doesn‚Äôt just check how often two items occur together ‚Äî\n",
        "it checks whether they occur together regularly and predictably over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Kh9sH9Aq2PwL",
        "outputId": "edc2f232-cf6b-4a3b-c8b4-926412dbcad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîπ Association Rules (A ‚Üí B) with TSI:\n",
            "+-------------+-------------+-------+--------------------+--------------------+--------------------+---+\n",
            "|Rule_A_to_B  |Rule_B_to_A  |support|confidence_A_to_B   |confidence_B_to_A   |lift                |TSI|\n",
            "+-------------+-------------+-------+--------------------+--------------------+--------------------+---+\n",
            "|27371 ‚Üí 27128|27128 ‚Üí 27371|0.25   |0.058823529411764705|0.5                 |0.11764705882352941 |1.0|\n",
            "|18375 ‚Üí 21516|21516 ‚Üí 18375|0.25   |0.3333333333333333  |0.07692307692307693 |0.10256410256410256 |1.0|\n",
            "|17158 ‚Üí 5433 |5433 ‚Üí 17158 |0.25   |0.2222222222222222  |0.1                 |0.08888888888888889 |1.0|\n",
            "|27128 ‚Üí 38347|38347 ‚Üí 27128|0.25   |0.5                 |0.044444444444444446|0.08888888888888889 |1.0|\n",
            "|9026 ‚Üí 47097 |47097 ‚Üí 9026 |0.25   |0.4                 |0.05263157894736842 |0.08421052631578947 |1.0|\n",
            "|30972 ‚Üí 44930|44930 ‚Üí 30972|0.25   |0.1                 |0.15384615384615385 |0.06153846153846154 |1.0|\n",
            "|44902 ‚Üí 4711 |4711 ‚Üí 44902 |0.25   |0.2                 |0.06451612903225806 |0.05161290322580645 |1.0|\n",
            "|1243 ‚Üí 43499 |43499 ‚Üí 1243 |0.25   |0.16666666666666666 |0.07692307692307693 |0.05128205128205128 |1.0|\n",
            "|10979 ‚Üí 6876 |6876 ‚Üí 10979 |0.25   |0.16666666666666666 |0.07142857142857142 |0.047619047619047616|1.0|\n",
            "|26434 ‚Üí 48039|48039 ‚Üí 26434|0.25   |0.25                |0.04081632653061224 |0.04081632653061224 |1.0|\n",
            "|20334 ‚Üí 4773 |4773 ‚Üí 20334 |0.25   |0.10526315789473684 |0.09523809523809523 |0.040100250626566414|1.0|\n",
            "|11319 ‚Üí 26434|26434 ‚Üí 11319|0.25   |0.14285714285714285 |0.05714285714285714 |0.0326530612244898  |1.0|\n",
            "|11113 ‚Üí 41796|41796 ‚Üí 11113|0.25   |0.043478260869565216|0.15384615384615385 |0.026755852842809364|1.0|\n",
            "|36692 ‚Üí 38824|38824 ‚Üí 36692|0.25   |0.046511627906976744|0.14285714285714285 |0.026578073089700997|1.0|\n",
            "|27589 ‚Üí 45806|45806 ‚Üí 27589|0.25   |0.2222222222222222  |0.027777777777777776|0.024691358024691357|1.0|\n",
            "|27460 ‚Üí 24050|24050 ‚Üí 27460|0.25   |0.09523809523809523 |0.06451612903225806 |0.02457757296466974 |1.0|\n",
            "|2880 ‚Üí 12806 |12806 ‚Üí 2880 |0.25   |0.058823529411764705|0.1                 |0.023529411764705882|1.0|\n",
            "|34819 ‚Üí 12900|12900 ‚Üí 34819|0.25   |0.05555555555555555 |0.1                 |0.022222222222222223|1.0|\n",
            "|270 ‚Üí 2097   |2097 ‚Üí 270   |0.25   |0.2857142857142857  |0.01904761904761905 |0.021768707482993196|1.0|\n",
            "|46561 ‚Üí 5433 |5433 ‚Üí 46561 |0.25   |0.05405405405405406 |0.1                 |0.021621621621621623|1.0|\n",
            "+-------------+-------------+-------+--------------------+--------------------+--------------------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import col, explode, collect_set, concat_ws, lit\n",
        "from pyspark.sql.types import ArrayType, StringType\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "# ---------------------------------------\n",
        "# 1Ô∏è‚É£ Define UDF to create item pairs per basket\n",
        "# ---------------------------------------\n",
        "def generate_pairs(items):\n",
        "    pairs = []\n",
        "    items = list(items)\n",
        "    for i in range(len(items)):\n",
        "        for j in range(i + 1, len(items)):\n",
        "            pairs.append((items[i], items[j]))\n",
        "    return pairs\n",
        "\n",
        "pairs_udf = udf(generate_pairs, ArrayType(ArrayType(StringType())))\n",
        "\n",
        "# ---------------------------------------\n",
        "# 2Ô∏è‚É£ Create all item pairs per order\n",
        "# ---------------------------------------\n",
        "order_pairs = (\n",
        "    order_products_all\n",
        "    .withColumn(\"product_id_str\", col(\"product_id\").cast(\"string\"))\n",
        "    .groupBy(\"order_id\", \"order_dow\")\n",
        "    .agg(collect_set(\"product_id_str\").alias(\"items\"))\n",
        "    .withColumn(\"pairs\", pairs_udf(col(\"items\")))\n",
        "    .select(\"order_dow\", explode(\"pairs\").alias(\"pair\"))\n",
        "    .select(\n",
        "        col(\"order_dow\"),\n",
        "        col(\"pair\").getItem(0).alias(\"itemA\"),\n",
        "        col(\"pair\").getItem(1).alias(\"itemB\")\n",
        "    )\n",
        ")\n",
        "\n",
        "# ---------------------------------------\n",
        "# 3Ô∏è‚É£ Frequency of pairs per day-of-week (for TSI)\n",
        "# ---------------------------------------\n",
        "pair_dow_counts = (\n",
        "    order_pairs.groupBy(\"itemA\", \"itemB\", \"order_dow\")\n",
        "    .count()\n",
        "    .withColumnRenamed(\"count\", \"freq_dow\")\n",
        ")\n",
        "\n",
        "# ---------------------------------------\n",
        "# 4Ô∏è‚É£ Compute mean, stddev and TSI for each pair\n",
        "# ---------------------------------------\n",
        "tsi_df = (\n",
        "    pair_dow_counts.groupBy(\"itemA\", \"itemB\")\n",
        "    .agg(\n",
        "        F.mean(\"freq_dow\").alias(\"mu\"),\n",
        "        F.stddev(\"freq_dow\").alias(\"sigma\")\n",
        "    )\n",
        "    .withColumn(\n",
        "        \"TSI\",\n",
        "        F.when(col(\"mu\") == 0, F.lit(0)).otherwise(1 - (col(\"sigma\") / col(\"mu\")))\n",
        "    )\n",
        ")\n",
        "\n",
        "# ---------------------------------------\n",
        "# 5Ô∏è‚É£ Compute overall frequencies for support/confidence/lift\n",
        "# ---------------------------------------\n",
        "pair_freq = (\n",
        "    order_pairs.groupBy(\"itemA\", \"itemB\").count().withColumnRenamed(\"count\", \"freq_pair\")\n",
        ")\n",
        "freqA = (\n",
        "    order_pairs.groupBy(\"itemA\").count().withColumnRenamed(\"count\", \"freqA\")\n",
        ")\n",
        "freqB = (\n",
        "    order_pairs.groupBy(\"itemB\").count().withColumnRenamed(\"count\", \"freqB\")\n",
        ")\n",
        "\n",
        "total_tx = order_pairs.select(\"order_dow\").distinct().count()  # total unique days (or use total orders if you prefer)\n",
        "\n",
        "# Join all frequency info\n",
        "rules_df = (\n",
        "    pair_freq\n",
        "    .join(freqA, on=\"itemA\")\n",
        "    .join(freqB, on=\"itemB\")\n",
        "    .join(tsi_df.select(\"itemA\", \"itemB\", \"TSI\"), on=[\"itemA\", \"itemB\"], how=\"left\")\n",
        ")\n",
        "\n",
        "# ---------------------------------------\n",
        "# 6Ô∏è‚É£ Compute Support, Confidence, Lift\n",
        "# ---------------------------------------\n",
        "rules_df = (\n",
        "    rules_df\n",
        "    .withColumn(\"support\", col(\"freq_pair\") / lit(total_tx))\n",
        "    .withColumn(\"confidence_A_to_B\", col(\"freq_pair\") / col(\"freqA\"))\n",
        "    .withColumn(\"confidence_B_to_A\", col(\"freq_pair\") / col(\"freqB\"))\n",
        "    .withColumn(\n",
        "        \"lift\",\n",
        "        (col(\"freq_pair\") / lit(total_tx)) /\n",
        "        ((col(\"freqA\") / lit(total_tx)) * (col(\"freqB\") / lit(total_tx)))\n",
        "    )\n",
        ")\n",
        "\n",
        "# ---------------------------------------\n",
        "# 7Ô∏è‚É£ Make readable rules and show\n",
        "# ---------------------------------------\n",
        "rules_df = (\n",
        "    rules_df\n",
        "    .withColumn(\"Rule_A_to_B\", concat_ws(\" ‚Üí \", col(\"itemA\"), col(\"itemB\")))\n",
        "    .withColumn(\"Rule_B_to_A\", concat_ws(\" ‚Üí \", col(\"itemB\"), col(\"itemA\")))\n",
        "    .select(\n",
        "        \"Rule_A_to_B\", \"Rule_B_to_A\", \"support\",\n",
        "        \"confidence_A_to_B\", \"confidence_B_to_A\",\n",
        "        \"lift\", \"TSI\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# ---------------------------------------\n",
        "# 8Ô∏è‚É£ Show results\n",
        "# ---------------------------------------\n",
        "print(\"üîπ Association Rules (A ‚Üí B) with TSI:\")\n",
        "rules_df.orderBy(col(\"TSI\").desc(), col(\"lift\").desc()).show(20, truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RACd0NUUBAlf"
      },
      "source": [
        "# METRIC - 3 - **Diversity Spread Index (DSI) - basket diversity score**\n",
        "\n",
        "* Basket-level DSI =DSI measures how diverse a single shopping basket is ‚Äî that is, how many different types (departments or categories) of products are present.\n",
        " * How broad or narrow the shopper‚Äôs interest is within a single purchase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rRs1P7Zn3RmK",
        "outputId": "6cff0245-56b2-4f15-fb79-91c30147da04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß∫ Basket-level Diversity Spread Index:\n",
            "+--------+-----------+-----------+-------------------+\n",
            "|order_id|unique_dept|total_items|DSI                |\n",
            "+--------+-----------+-----------+-------------------+\n",
            "|12799   |7          |13         |0.5                |\n",
            "|35947   |6          |11         |0.5                |\n",
            "|37489   |12         |39         |0.3                |\n",
            "|31983   |4          |12         |0.3076923076923077 |\n",
            "|4900    |7          |24         |0.28               |\n",
            "|35071   |2          |3          |0.5                |\n",
            "|22521   |5          |16         |0.29411764705882354|\n",
            "|31261   |5          |9          |0.5                |\n",
            "|12046   |3          |12         |0.23076923076923078|\n",
            "|20497   |4          |9          |0.4                |\n",
            "+--------+-----------+-----------+-------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "\n",
            "üë• User-level Average DSI:\n",
            "+-------+------------------+\n",
            "|user_id|avg_DSI           |\n",
            "+-------+------------------+\n",
            "|20548  |0.8888888888888888|\n",
            "|14630  |0.8888888888888888|\n",
            "|8422   |0.8888888888888888|\n",
            "|3210   |0.875             |\n",
            "|219    |0.875             |\n",
            "|17540  |0.875             |\n",
            "|19568  |0.875             |\n",
            "|6636   |0.875             |\n",
            "|8944   |0.875             |\n",
            "|964    |0.875             |\n",
            "+-------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import countDistinct, avg, col\n",
        "\n",
        "# Compute basket diversity for each cleaned order\n",
        "basket_div = (\n",
        "    clean_df.groupBy(\"order_id\")\n",
        "    .agg(\n",
        "        countDistinct(\"department_id\").alias(\"unique_dept\"),\n",
        "        countDistinct(\"product_id\").alias(\"total_items\")\n",
        "    )\n",
        "    .withColumn(\"DSI\", col(\"unique_dept\") / (col(\"total_items\") + 1))\n",
        ")\n",
        "\n",
        "# Compute average DSI per user (optional)\n",
        "user_div = (\n",
        "    basket_div.join(\n",
        "        orders.select(\"order_id\", \"user_id\"), \"order_id\", \"left\"\n",
        "    )\n",
        "    .groupBy(\"user_id\")\n",
        "    .agg(avg(\"DSI\").alias(\"avg_DSI\"))\n",
        "    .orderBy(col(\"avg_DSI\").desc())\n",
        ")\n",
        "\n",
        "# Show results\n",
        "print(\"üß∫ Basket-level Diversity Spread Index:\")\n",
        "basket_div.show(10, truncate=False)\n",
        "\n",
        "print(\"\\nüë• User-level Average DSI:\")\n",
        "user_div.show(10, truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "measures the average DSI across all the baskets of a user.\n",
        "\n",
        "This gives you an overall user profile:\n",
        "\n",
        "High average DSI ‚Üí shopper who buys many types of products (generalist)\n",
        "\n",
        "Low average DSI ‚Üí shopper who sticks to one category (specialist)"
      ],
      "metadata": {
        "id": "aVkpgUOdXq9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRADIENT BOOSTING CLASSFIIER -\n",
        "  \n",
        "  **\"Predicting Product Reorders Using Gradient Boosted Trees Based on User Purchase Behavior Parameters (like total purchases, cart position, order time, and reorder gap), with Feature Importance Analysis to Identify Key Buying Patterns.\"**\n"
      ],
      "metadata": {
        "id": "b9BDu4MkbK0j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JnoPKRiM-mUz"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import col, count, avg, max, min\n",
        "\n",
        "# Merge product and order info for feature creation\n",
        "train_df = (\n",
        "    order_products__prior\n",
        "    .join(orders.select(\"order_id\", \"user_id\", \"order_dow\", \"order_hour_of_day\", \"days_since_prior_order\"), \"order_id\", \"left\")\n",
        "    .join(products.select(\"product_id\", \"aisle_id\", \"department_id\"), \"product_id\", \"left\")\n",
        "    .filter(col(\"reordered\").isNotNull())  # keep only rows with reorder info\n",
        ")\n",
        "\n",
        "# Aggregate user-level and product-level behavioral features\n",
        "features_df = (\n",
        "    train_df.groupBy(\"user_id\", \"product_id\")\n",
        "    .agg(\n",
        "        count(\"*\").alias(\"total_purchases\"),\n",
        "        avg(\"add_to_cart_order\").alias(\"avg_cart_position\"),\n",
        "        avg(\"order_dow\").alias(\"avg_order_dow\"),\n",
        "        avg(\"order_hour_of_day\").alias(\"avg_order_hour\"),\n",
        "        avg(\"days_since_prior_order\").alias(\"avg_days_between_orders\"),\n",
        "        F.max(\"reordered\").alias(\"label\")  # 1 if ever reordered\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "efayGhRm-rg1"
      },
      "outputs": [],
      "source": [
        "features_df = features_df.fillna({\"avg_days_between_orders\": 0})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RTH_Gdgd_Lzw"
      },
      "outputs": [],
      "source": [
        "# Fill nulls with 0 or column means\n",
        "features_df = features_df.fillna({\n",
        "    \"total_purchases\": 0,\n",
        "    \"avg_cart_position\": 0,\n",
        "    \"avg_order_dow\": 0,\n",
        "    \"avg_order_hour\": 0,\n",
        "    \"avg_days_between_orders\": 0,\n",
        "    \"label\": 0\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xY1J1_IO-uIT"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\n",
        "        \"total_purchases\",\n",
        "        \"avg_cart_position\",\n",
        "        \"avg_order_dow\",\n",
        "        \"avg_order_hour\",\n",
        "        \"avg_days_between_orders\"\n",
        "    ],\n",
        "    outputCol=\"features\",\n",
        "    handleInvalid=\"keep\"   # <- prevents failure if nulls still exist\n",
        ")\n",
        "\n",
        "final_df = assembler.transform(features_df).select(\"user_id\", \"product_id\", \"features\", \"label\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o3r5I4sk-wWv"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = final_df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "\n",
        "gbt = GBTClassifier(\n",
        "    labelCol=\"label\",\n",
        "    featuresCol=\"features\",\n",
        "    maxIter=50,\n",
        "    maxDepth=5,\n",
        "    stepSize=0.1,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "gbt_model = gbt.fit(train_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZtElv1yI_hqq",
        "outputId": "8c0a07ff-f9ed-4907-e0c6-21cd43846fd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ AUC: 0.7687\n",
            "‚úÖ PR-AUC: 0.8600\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "predictions = gbt_model.transform(test_data)\n",
        "\n",
        "# Evaluate AUC and Accuracy\n",
        "evaluator_auc = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "auc = evaluator_auc.evaluate(predictions)\n",
        "\n",
        "evaluator_pr = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderPR\")\n",
        "pr_auc = evaluator_pr.evaluate(predictions)\n",
        "\n",
        "print(f\"‚úÖ AUC: {auc:.4f}\")\n",
        "print(f\"‚úÖ PR-AUC: {pr_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Imaq4P8f_4r-",
        "outputId": "d12b6287-81f5-4a68-dd1e-01fb981c9b7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç Feature Importances:\n",
            "total_purchases: 0.5048\n",
            "avg_cart_position: 0.0735\n",
            "avg_order_dow: 0.0641\n",
            "avg_order_hour: 0.1707\n",
            "avg_days_between_orders: 0.1870\n"
          ]
        }
      ],
      "source": [
        "feature_importances = list(zip(\n",
        "    assembler.getInputCols(),\n",
        "    gbt_model.featureImportances.toArray()\n",
        "))\n",
        "\n",
        "print(\"\\nüîç Feature Importances:\")\n",
        "for feature, importance in feature_importances:\n",
        "    print(f\"{feature}: {importance:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeyL2m5NFygB"
      },
      "source": [
        "This extracts how important each feature is for the model.\n",
        "\n",
        "Feature\tImportance\tMeaning\n",
        "total_purchases\t0.5790\tMost influential ‚Äî frequent buyers behave consistently.\n",
        "avg_cart_position\t0.1093\tSomewhat relevant ‚Äî maybe early cart positions indicate priority.\n",
        "avg_order_dow\t0.0652\tSlightly influences ‚Äî weekday pattern of orders.\n",
        "avg_order_hour\t0.1074\tModerate ‚Äî ordering time has some predictive power.\n",
        "avg_days_between_orders\t0.1391\tSignificant ‚Äî regular vs irregular buyers."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}